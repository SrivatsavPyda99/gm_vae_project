{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dim = 28\n",
    "flat_img_size = mnist_dim*mnist_dim\n",
    "k = 100 # size of input to generator\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super(decoder, self).__init__()\n",
    "        self.mnist_dim = mnist_dim\n",
    "        self.fc1 = nn.Linear(k, num_hidden)\n",
    "        self.bn1 = nn.BatchNorm1d(num_hidden, momentum=0.8)\n",
    "        self.fc2 = nn.Linear(num_hidden, 2*num_hidden)\n",
    "        self.bn2 = nn.BatchNorm1d(2*num_hidden, momentum=0.8)\n",
    "        self.fc3 = nn.Linear(2*num_hidden, 4*num_hidden)\n",
    "        self.bn3 = nn.BatchNorm1d(4*num_hidden, momentum=0.8)\n",
    "        self.fc4 = nn.Linear(4*num_hidden, flat_img_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(F.leaky_relu(self.fc1(x), 0.2))\n",
    "        x = self.bn2(F.leaky_relu(self.fc2(x), 0.2))\n",
    "        x = self.bn3(F.leaky_relu(self.fc3(x), 0.2))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        x = x.view(-1, self.mnist_dim, self.mnist_dim)\n",
    "        return x\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super(encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(flat_img_size, 2*num_hidden)\n",
    "        self.fc2 = nn.Linear(2*num_hidden, num_hidden)\n",
    "        self.fc31 = nn.Linear(num_hidden, k)\n",
    "        self.fc32 = nn.Linear(num_hidden, k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Assumes x is an image\n",
    "        \"\"\"\n",
    "        x = x.view(-1, flat_img_size)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        logvar = F.sigmoid(self.fc31(x))\n",
    "        mu = F.sigmoid(self.fc32(x))\n",
    "        return mu, logvar\n",
    "    \n",
    "class vae(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super(vae, self).__init__()\n",
    "        self.encoder = encoder(num_hidden)\n",
    "        self.decoder = decoder(num_hidden)\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # to recreate: N(0, 1) * var(e ^{0.5 * unif(0, 1)}) + unif(0, 1)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = Variable(torch.randn(std.shape))\n",
    "        return eps.mul(std).add_(mu)\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.decoder(z)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    #BCE = F.binary_cross_entropy(recon_x.view(-1, flat_img_size), x.view(-1, flat_img_size), reduction='sum')\n",
    "    BCE = F.binary_cross_entropy(recon_x.view(-1, flat_img_size), x.view(-1, flat_img_size))\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(m, k):\n",
    "    \"\"\"\n",
    "    m = number of samples (batch size)\n",
    "    k = dimension per sample (should probably be around 100)\n",
    "    returns a numpy array of size m*k of (gaussian) noise to be input to the generator\n",
    "    \"\"\"\n",
    "    return torch.Tensor(np.random.normal(size=(m, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmax_iterations = 1000000\\nlr = 0.0002\\nbetas = (0.5, 0.999)\\nprint_interval = 100\\nsave_interval = 1000\\nprobability_interval=100\\nnum_hidden= 256\\nroot = \"~/Data/MNIST\"\\nsave_dir = \"Desktop/gm_vae_project/checkpoints/checkpoint_{}_layers\".format(num_hidden)\\nnum_gen = 10 # number of samples to generate at save intervals\\ngen_steps = 1  # number of generator updates per discriminator update\\ntraining_size=60000\\n\\n\\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\\nmnist_data = torchvision.datasets.MNIST(root, transform=transform, download=True)\\nmnist_loader = torch.utils.data.DataLoader(mnist_data, \\n                batch_size=batch_size, \\n                sampler=torch.utils.data.sampler.SubsetRandomSampler(np.random.choice(range(len(mnist_data)), \\n                                                                                      training_size)))\\n\\n'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "max_iterations = 1000000\n",
    "lr = 0.0002\n",
    "betas = (0.5, 0.999)\n",
    "print_interval = 100\n",
    "save_interval = 1000\n",
    "probability_interval=100\n",
    "num_hidden= 256\n",
    "root = \"~/Data/MNIST\"\n",
    "save_dir = \"Desktop/gm_vae_project/checkpoints/checkpoint_{}_layers\".format(num_hidden)\n",
    "num_gen = 10 # number of samples to generate at save intervals\n",
    "gen_steps = 1  # number of generator updates per discriminator update\n",
    "training_size=60000\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "mnist_data = torchvision.datasets.MNIST(root, transform=transform, download=True)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_data, \n",
    "                batch_size=batch_size, \n",
    "                sampler=torch.utils.data.sampler.SubsetRandomSampler(np.random.choice(range(len(mnist_data)), \n",
    "                                                                                      training_size)))\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(images_remade, vae, num_gen, base_dir, save_iter, loss_log, mu_log, logvar_log):\n",
    "    \"\"\"\n",
    "    1. Creates a new directory corresponding to the current iteration\n",
    "    2. saves discriminator and generator parameters\n",
    "    3. samples num_samples images from the generator\n",
    "    4. saves \"objective\" function over time\n",
    "    5. saves gradient norms over time\n",
    "    6. saves discriminator accuracies on both true and fake data over time\n",
    "    \"\"\"\n",
    "    \n",
    "    base_dir = os.path.join(base_dir, \"checkpoint_{}\".format(save_iter))\n",
    "    vae_ckpt = os.path.join(base_dir, \"vae_ckpt_{}.pkl\".format(save_iter))\n",
    "    reconstructed_images_dir = os.path.join(base_dir, \"reconstructed_images\")\n",
    "    new_images_dir = os.path.join(base_dir, \"new_images\")\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(base_dir):\n",
    "        os.mkdir(base_dir)\n",
    "    if not os.path.exists(reconstructed_images_dir):\n",
    "        os.mkdir(reconstructed_images_dir)\n",
    "    if not os.path.exists(new_images_dir):\n",
    "        os.mkdir(new_images_dir)\n",
    "        \n",
    "    # Stuff to save in base directory\n",
    "    \n",
    "    torch.save(vae.state_dict(), vae_ckpt)\n",
    "    np.save(os.path.join(base_dir, \"loss_log.npy\"), loss_log)\n",
    "    np.save(os.path.join(base_dir, \"mu_log.npy\"), mu_log)\n",
    "    np.save(os.path.join(base_dir, \"logvar_log.npy\"), logvar_log)\n",
    "    \n",
    "    # Reconstructed images\n",
    "    indices = np.random.choice(range(images_remade.shape[0]), num_gen)\n",
    "    for j in range(num_gen):\n",
    "        index = indices[j]\n",
    "        img = images_remade[index].data.numpy()\n",
    "        img = np.stack((img, img, img), axis=-1)\n",
    "        plt.imsave(os.path.join(reconstructed_images_dir, \"ckpt_{}_remade_img_{}.png\".format(save_iter, j+1)), img, cmap=\"gray\")\n",
    "        \n",
    "    # New images\n",
    "\n",
    "    Z = Variable(sample_z(num_gen, k))\n",
    "    Y = vae.decoder(Z)\n",
    "    for j in range(num_gen):\n",
    "        img = Y[j].data.numpy()\n",
    "        img = np.stack((img, img, img), axis=-1)\n",
    "        #img = vutils.make_grid(torch.from_numpy(img), normalize=True, scale_each=True)\n",
    "        plt.imsave(os.path.join(new_images_dir, \"ckpt_{}_new_img_{}.png\".format(save_iter, j+1)), img, cmap=\"gray\")\n",
    "        #writer.add_image('Image', img, save_iter)\n",
    "\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(range(0, save_iter, probability_interval), approximate_distinguishing_probs)\n",
    "    #fig.suptitle('Gen_Cap {}, Disc_Cap {}'.format(num_hidden_gen, num_hidden_disc), fontsize=20)\n",
    "    #plt.xlabel('iteration', fontsize=18)\n",
    "    #plt.ylabel('Distinguishing Probability', fontsize=16)\n",
    "    #fig.savefig(os.path.join(direct, \"dist_prob_gen_{}_disc_{}\".format(num_hidden_gen, num_hidden_disc)))\n",
    "    \n",
    "    #writer.add_scalar(\"objective\", values.mean(), save_iter)\n",
    "    #writer.add_scalar(\"discriminator gradient norms\", discrim_grad_norms.mean(), save_iter)\n",
    "    #writer.add_scalar(\"generator gradient norms\", gen_grad_norms.mean(), save_iter)\n",
    "    #writer.add_scalar(\"fake accuracies\", fake_accuracies.mean(), save_iter)\n",
    "    #writer.add_scalar(\"real accuracies\", real_accuracies.mean(), save_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################\n",
      "step 100/1000000. average loss of last 100 steps: \n",
      " 80.7739\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "######################\n",
      "step 200/1000000. average loss of last 100 steps: \n",
      "-0.2018\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "######################\n",
      "step 300/1000000. average loss of last 100 steps: \n",
      "-1.6256\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "######################\n",
      "step 400/1000000. average loss of last 100 steps: \n",
      "-3.4187\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "######################\n",
      "step 500/1000000. average loss of last 100 steps: \n",
      "-5.9063\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "######################\n",
      "step 600/1000000. average loss of last 100 steps: \n",
      "-8.5345\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 1000000\n",
    "lr = 0.0002\n",
    "betas = (0.5, 0.999)\n",
    "print_interval = 100\n",
    "save_interval = 1000\n",
    "probability_interval=100\n",
    "num_hidden= 256\n",
    "root = \"~/Data/MNIST\"\n",
    "save_dir = \"/Users/srivatsavpyda/Desktop/gm_vae_project/checkpoints/vae_{}\".format(num_hidden)\n",
    "num_gen = 10 # number of samples to generate at save intervals\n",
    "gen_steps = 1  # number of generator updates per discriminator update\n",
    "training_size=60000\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "mnist_data = torchvision.datasets.MNIST(root, transform=transform, download=True)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_data, \n",
    "                batch_size=batch_size, \n",
    "                sampler=torch.utils.data.sampler.SubsetRandomSampler(np.random.choice(range(len(mnist_data)), \n",
    "                                                                                      training_size)))\n",
    "\n",
    "vae = vae(num_hidden)\n",
    "\n",
    "loss_log = []\n",
    "mu_log = []\n",
    "logvar_log = []\n",
    "\n",
    "# Load checkpoint if given\n",
    "if checkpoint > 0:\n",
    "    direct = os.path.join(save_dir, \"checkpoint_{}\".format(checkpoint))\n",
    "    vae_ckpt = os.path.join(direct, \"vae_ckpt_{}.pkl\".format(checkpoint))\n",
    "    loss_log_ckpt = os.path.join(direct, \"loss_log.npy\")\n",
    "    mu_log_ckpt = os.path.join(direct, \"mu_log.npy\")\n",
    "    logvar_log_ckpt = os.path.join(direct, \"logvar_log.npy\")\n",
    "    vae.load_state_dict(torch.load(vae_ckpt))\n",
    "    loss_log = np.load(loss_log_ckpt).tolist()\n",
    "    mu_log = np.load(mu_log_ckpt).tolist()\n",
    "    logvar_log = np.load(logvar_log_ckpt).tolist()\n",
    "\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "\n",
    "running_value = 0\n",
    "\n",
    "# training loop\n",
    "for t in range(max_iterations):\n",
    "    it = t + checkpoint\n",
    "    \n",
    "    images, _ = next(iter(mnist_loader)) # get some examples (ignore labels)\n",
    "    images = Variable(images)\n",
    "\n",
    "    images_remade, mu, logvar = vae(images)\n",
    "\n",
    "    vae_loss = loss_function(images_remade, images, mu, logvar)\n",
    "    \n",
    "    loss_log.append(vae_loss.data.numpy())\n",
    "    mu_log.append(mu.data.numpy())\n",
    "    logvar_log.append(logvar.data.numpy())\n",
    "    \n",
    "    running_value += vae_loss.data\n",
    "\n",
    "    vae.zero_grad()\n",
    "    vae_loss.backward()\n",
    "    vae_optimizer.step()\n",
    "\n",
    "    if (it+1) % print_interval == 0:\n",
    "        # also check disciminator and generator gradient magnitudes\n",
    "        #discrim_grad_norm = np.sqrt(np.sum([np.linalg.norm(x.grad.data)**2 for x in discriminator.parameters()]))\n",
    "\n",
    "        # check how disciminator is doing in terms of accuracy\n",
    "        #real_accuracy = (x_probs.data.numpy() > 0.5).mean()\n",
    "        #fake_accuracy = (y_probs.data.numpy() <= 0.5).mean()\n",
    "        #avg_accuracy = (real_accuracy + fake_accuracy)/2\n",
    "        #avg_fake_prob = y_probs.data.numpy().mean()\n",
    "        #avg_real_prob = x_probs.data.numpy().mean()\n",
    "\n",
    "        #real_accuracies.append(real_accuracy)\n",
    "        #fake_accuracies.append(fake_accuracy)\n",
    "        #avg_accuracies.append(avg_accuracy)\n",
    "        #avg_fake_probs.append(avg_fake_prob)\n",
    "        #avg_real_probs.append(avg_real_prob)\n",
    "        #discrim_grad_norms.append(discrim_grad_norm)\n",
    "\n",
    "        print(\"######################\")\n",
    "        print(\"step {}/{}. average loss of last {} steps: {}\".format(it+1, max_iterations, print_interval,\n",
    "                                                                    running_value/print_interval))\n",
    "        #print(\"fraction discriminator correct on real: {}, and fake: {}\".format(real_accuracy, fake_accuracy))\n",
    "        #print(\"average prob on real: {}, and fake: {}\".format(avg_real_prob, avg_fake_prob))\n",
    "        #print(\"discriminator gradient squared norm: {}\".format(discrim_grad_norm))\n",
    "        running_value = 0\n",
    "\n",
    "\n",
    "    #if (it+1) % probability_interval == 0:\n",
    "    #    approximate_distinguishing_probs.append(approximate_distinguishing_prob(discriminator, generator, mnist_data))\n",
    "    # save ocasionally and save a few sample images generated\n",
    "    if (it+1) % save_interval == 0:\n",
    "        save_checkpoint(images_remade, vae, num_gen, save_dir, it+1, loss_log, mu_log, logvar_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
